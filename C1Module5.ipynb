{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics in the Notebook: \n",
    "- Read the list of images sing queues and coordinators\n",
    "- Resize the images to the same dimensions\n",
    "- show the images in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ku.kulshrestha\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ku.kulshrestha\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ku.kulshrestha\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ku.kulshrestha\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ku.kulshrestha\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ku.kulshrestha\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_list = ['droplets.jpg', 'leaf.jpg', 'night_boat.jpg', 'tiger.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a queue of file names of images\n",
    "filename_queue = tf.train.string_input_producer(original_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file \n",
    "image_reader = tf.WholeFileReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    #Coordinate the loading of image files\n",
    "    coord = tf.train.Coordinator()   #It abstracts away all queue working in multiple threads\n",
    "    threads = tf.train.start_queue_runners(sess = sess, coord = coord) #starting all of the threads\n",
    "    \n",
    "    image_list = []\n",
    "    for i in range(len(original_image_list)): \n",
    "        #reading the whole file from the queue\n",
    "        _, image_file = image_reader.read(filename_queue)\n",
    "        #decode the jpeg image and convert it into a tensor\n",
    "        image = tf.image.decode_jpeg(image_file)\n",
    "        #resizing the image\n",
    "        image = tf.image.resize_images(image, [224, 224])\n",
    "        image.set_shape((224, 224, 3))\n",
    "        \n",
    "        #execute the computation graph\n",
    "        image_array = sess.run(image)\n",
    "        print(image_array.shape)\n",
    "        \n",
    "        #Displaying the resized image\n",
    "        Image.fromarray(image_array.astype('uint8'), 'RGB').show()\n",
    "        \n",
    "        #We want every image to be represented by a single 4 dimensional tensor \n",
    "        #with first element reflecting which image number it is.\n",
    "        image_list.append(tf.expand_dims(image_array, 0))\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    #Representing the image in tnsorboard\n",
    "    index = 0\n",
    "    \n",
    "    #Write image summary\n",
    "    summary_writer = tf.summary.FileWriter('./m4_example2', graph = sess.graph)\n",
    "    \n",
    "    for image_tensor in image_list: \n",
    "        summary_str = sess.run(tf.summary.image(\"image-\" + str(index), image_tensor))\n",
    "        summary_writer.add_summary(summary_str)\n",
    "        index +=1 \n",
    "    \n",
    "    summary_writer.close() \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of images as 4D tensors with Image transformations\n",
    "\n",
    "If we have to represent all images in the same 4D tensor, all of them need to be of same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (10, 6, 6, 3) --> Here 3 represents the channels, and 10 represents the total images and 6x6 being the size of each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "original_image_list = ['droplets.jpg', 'leaf.jpg', 'night_boat.jpg', 'tiger.jpg']\n",
    "\n",
    "#make a queue of file names of images\n",
    "filename_queue = tf.train.string_input_producer(original_image_list)\n",
    "\n",
    "#Read the file \n",
    "image_reader = tf.WholeFileReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 112, 3)\n",
      "(112, 112, 3)\n",
      "(112, 112, 3)\n",
      "(112, 112, 3)\n",
      "Tensor(\"stack_12:0\", shape=(4, 112, 112, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    #Coordinate the loading of image files\n",
    "    coord = tf.train.Coordinator()   #It abstracts away all queue working in multiple threads\n",
    "    threads = tf.train.start_queue_runners(sess = sess, coord = coord) #starting all of the threads\n",
    "    \n",
    "    image_list = []\n",
    "    for i in range(len(original_image_list)): \n",
    "        #reading the whole file from the queue\n",
    "        _, image_file = image_reader.read(filename_queue)\n",
    "        #decode the jpeg image and convert it into a tensor\n",
    "        image = tf.image.decode_jpeg(image_file)\n",
    "        #resizing the image\n",
    "        image = tf.image.resize_images(image, [224, 224])\n",
    "        image.set_shape((224, 224, 3))\n",
    "        \n",
    "        #To flip the image up and down\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        \n",
    "        #image cropped from center\n",
    "        image = tf.image.central_crop(image, central_fraction=0.5)\n",
    "        \n",
    "        #execute the computation graph\n",
    "        image_array = sess.run(image)\n",
    "        print(image_array.shape)\n",
    "\n",
    "        #image array is a numpy array and we want to convert it to a tensor\n",
    "        image_tensor = tf.stack(image_array)\n",
    "        \n",
    "        #We want every image to be represented by a single 4 dimensional tensor \n",
    "        #with first element reflecting which image number it is.\n",
    "        image_list.append(image_tensor)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "    #converts all tensors to a single tensor of 4 dimension:\n",
    "    image_tensor = tf.stack(image_list)\n",
    "    print(image_tensor)\n",
    "    \n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter('./m4_example3', graph = sess.graph)\n",
    "    \n",
    "    summary_str = sess.run(tf.summary.image(\"images\", image_tensor, max_outputs=4))\n",
    "    summary_writer.add_summary(summary_str)\n",
    "    \n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
